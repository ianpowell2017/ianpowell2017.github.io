[ { "title": "SSL certificate install", "url": "/posts/ssl-certificate-install/", "categories": "learning", "tags": "ssl", "date": "2022-06-23 12:32:00 +0100", "snippet": "SSL CertificatesWhy?An SSL certificate encrypts content sent from Server to Client and Client to server. It prevents Man in the middle attacks and instils confidence in the user as a lock icon will appear in the address bar of the browser.The renewal process - Start earlyCAUTION : There are multiple steps to perform before actually receiving the SSL certificate so start early (ideally two weeks before expiry), if you are complete within this time then great, if you are late then customers will not be able to access the website until a certificate is applied, example below.A wildcard certificate (*.domain.com) is one that can be used on many subdomains and therefore protects any subdomain we choose. www.domain.com test.domain.comStep 1 - Purchase certificateWhen going through the steps, you will be advise you to download a key file STAR.domain.com_key.txt, you will need this when applying the certificate. You must keep this file in a secure safe place as it is the private key file which unlocks the certificate issued later, you will not be able to download this again.Step 2 - Business ValidationOne important requirement of an Domain EV certificate is the business validation process. This requires the certificate company to verify the company actually exists and is registered and you are the company.During the validation process, an email is sent to the registered business who arranges a time and date when they should receive a phone call to preform the validation. The phone number must be registered to the company and therefore you cannot give your mobile to try and short circuit this process.Once validation is complete, the issuer will issue the certificate.Step 3 - Download and modify the filesIn the download bundle file STAR.domain.com_cert.zip there will be three files STAR.domain.com.ca-bundle - The link STAR.domain.com.crt - The actual certificate STAR.domain.com.p7b - You won’t need thisOpen STAR.domain.com.crt in an text editor and copy and paste the contents of STAR.domain.com.ca-bundle to the end of STAR.domain.com.crt When an operating system is deployed is comes with various trusted root certificates. Every certificate issued must trace back to one of these root certificates (Certification Path) for it to be considered as valid. The ca-bundle file performs this vital process.Step 4 - Installing the filesAt this point you should have the following files STAR.domain.com.crt - This is both files STAR.domain.com.crt + STAR.domain.com.ca-bundle concatenated. STAR.domain.com_key.txt - Retrieved from that safe place you put it before the business validation process began.Upload these to your cloud provider." }, { "title": "Centos 8 notes", "url": "/posts/linux-centos-notes/", "categories": "linux", "tags": "centos, centos8, learning", "date": "2022-06-23 11:32:00 +0100", "snippet": "Using Centos 8 notesDownload and install ‘BitVise Windows SSH Client’ New SFTP window for drag and drop upload / download / Erase / Rename New terminal console for cmd access.Note: Linux is CASE SENSITIVE, file.txt and File.txt are can be two separate files.General cd - To navigate folder structureeg. cd /nas/nopCommerce-test ls - To list files / folders in directory ls -la - To list files / folders with information of who owns the files and byte size and timestamp pwd - To display current path exit - Ends terminal sessionOwnership sudo chown www-data:www-data _filenamehere_ - Change ownership of files in _filenamehere_ to belong to www-data NOTE: When files are uploaded using the drag and drop (scp) files are written using your account. For Kestrel to be able to run / access then, the ownership needs to be changed to the account which kestrel runs under www-data Start / Stop / Status of running daemon process sudo systemctl start _servicenamehere_.service - This command starts the daemon service called _servicenamehere_.serviceStarts the kestrel instance daemon process sudo systemctl stop _servicenamehere_.service - This command stops the daemon service called _servicenamehere_.service sudo journalctl -fu _servicenamehere_ - Tails the STDOUT / STDERR from the service called _servicenamehere_ CTRL-C to end console output. Miscellaneous du -cha --max-depth=1 / | grep -E \"M|G\" - To find out where disk space is being used from root directory folder du -cha --max-depth=1 /var/nginx | grep -E \"M|G\" - To find out where disk space is being used from /var/nginx directory folderPeriodic maintenance sudo yum update answer y when prompted sudo yum upgrade answer y when promptedImportant directories/etc/systemd/system - Contains the service daemon files which run the applications and restart the apps on crash" }, { "title": "Adding Redux to a React app", "url": "/posts/adding-redux-to-a-react-site/", "categories": "learning", "tags": "js, react-js", "date": "2022-06-10 18:32:00 +0100", "snippet": "Why do we need Redux in a React app?In a large application you will commonly have a large amount of state. The solutions are either to have the state in the most parent component and pass the values down via props or each component has local state. Passing as props becomes problematic on pages with many controls. Components managing own state causes problem if needed to be modified at a different location in the page.The solution therefore is to use Redux which defines specific Actions and Reducers to manage access to state.Getting started In Visual Studio Code, open command line to the root of the React project and runnpm install redux react-redux Inside the src folder, create store.jsimport { createStore, combineReducers } from 'redux';import { todos } from './todos/reducers'; // Include reducersconst reducers = { todos,};const rootReducer = combineReducers(reducers);export const configureStore = () =&gt; createStore(rootReducer);Open index.js and addimport { Provider } from 'react-redux';import { configureStore } from './store';Wrap the &lt;App /&gt;ReactDOM.render( &lt;Provider store={configureStore()} &gt; &lt;App /&gt; &lt;/Provider&gt;, document.getElementById('root'),);See more in the attended learning course examples -&gt; CH03To maintain state across browser refreshes use Redux Persistnpm install redux-persistUpdate store.jsimport { persistReducer } from 'redux-persist';import storage from 'redux-persist/lib/storage';import autoMergeLevel2 from 'redux-persist/lib/stateReconciler/autoMergeLevel2';const rootReducer = combineReducers(reducers);const persistConfig = { key: 'root', storage, // Defaults to local storage in the browser stateReconciler: autoMergeLevel2,};const persistedReducer = persistReducer(persistConfig, rootReducer);export const configureStore = () =&gt; createStore(persistedReducer);Update index.jsimport { persistStore } from 'redux-persist';import { PersistGate } from 'redux-persist/lib/integration/react';const store = configureStore();const persistor = persistStore(store);ReactDOM.render( &lt;Provider store={store}&gt; &lt;PersistGate loading={&lt;div&gt;Loading...&lt;/div&gt;} persistor={persistor}&gt; &lt;App /&gt; &lt;/PersistGate&gt; &lt;/Provider&gt;, document.getElementById('root'),);Redux DevToolsAdd this Chrome extension to make development with Redux easier!Also update store.jsexport const configureStore = () =&gt; createStore( persistedReducer, window.__REDUX_DEVTOOLS_EXTENSION__ &amp;&amp; window.__REDUX_DEVTOOLS_EXTENSION__(), // This connects our app to the redux extension );Redux Best Practices Export the connected and unconnected versions of a component export const TodoList = ... So we can test the component as is export default connect(mapStateToProps, mapDispatchToProps)(TodoList); For the application Keep Redux actions and async operations out of your reducers Think carefully about connecting components - ‘Connecting a component can, in practice, make it less reusable.’Why use a side-effect libraryMove data fetching or sending outside of a component, components should only be responsible to displaying or taking user input, into a side effect library like Redux Thunk or Redux Saga. Redux Thunk is a simpler library to learn.Install and configure Redux ThunkSee CH04 in the example bundlenpm install redux-thunk redux-devtools-extension @babel/runtimenpm install --save-dev @babel/plugin-transform-runtimeopen .babelrc file{ \"presets@: [\"@babel/preset-env\", \"@babel/preset-react\"], \"plugins\": [\"@babel/plugin-transform-runtime\"]}open store.jsimport { createStore, combineReducers, applyMiddleware } from 'redux';import thunk from 'redux-thunk';import { composeWithDevTools } from 'redux-devtools-extension';Update following sectionexport const configureStore = () =&gt; createStore( persistedReducer, composeWithDevTools( applyMiddleware(thunk) ) );Add first simple thunkCreate thunk.jsexport const displayAlert = () = () =&gt; { alert(\"Hello!\");}Open a React component and addimport { displayAlert } from './thunks';const mapStateToProps = state = ({ todos: state.todos,});const mapDispatchToProps = dispatch =&gt; ({ onRemovePressed: text =&gt; dispatch(removeTodo(text)), onCompletedPressed: text =&gt; dispatch(markTodoAsCompleted(text)), onDisplayAlertClicked: () =&gt; dispatch(displayAlert()),})Async thunkAdd to thunk.jsimport { loadTodosInProgress, loadTodosSuccess, loadTodosFailure} from './actions';export const loadTodos = () =&gt; async (dispatch, getState) =&gt; { try { dispatch(loadTodosInProgress()); const response = await fetch('http://localhost:8080/todos'); const todos = await response.json(); dispatch(loadTodosSuccess(todos)); } catch (e) { dispatch(loadTodosFailure()); dispatch(displayAlert(e)); } }export const displayAlert = text =&gt; () =&gt; { alert(text);}SelectorsSelectors give us a place to put logic for combining, filtering, transforming storing data. This way if/when the way the data is stored in state changes, you only have to update the selectors.js fileSee CH05 in the example bundleCreate selectors.jsexport const getToDos = state =&gt; state.todos;export const getToDosLoading = state =&gt; state.isLoading;Replaceconst mapStateToProps = state = ({ isLoading: state.isLoading, todos: state.todos,});withimport { getToDos, getToDosLoading } from './selectors';const mapStateToProps = state = ({ isLoading: getToDosLoading(state), todos: getToDos(state),});ReselectEnables you to create more complicated selectors, additionally it has the extra benefit not re-computing the selector IF the data in state hasn’t changed, it gives the previously computed value.Installnpm install reselectimport { createSelector } from 'reselect';export const getToDos = state =&gt; state.todos.data;export const getToDosLoading = state =&gt; state.todos.isLoading;export const getIncompleteTodos = createSelector( getTodos, (todos) =&gt; todos.filter(todo =&gt; !todo.isCompleted),)The final parameter in the createSelector method gets all the previous values as arguments into the function specified.import { createSelector } from 'reselect';export const getToDos = state =&gt; state.todos.data;export const getToDosLoading = state =&gt; state.todos.isLoading;export const getIncompleteTodos = createSelector( getTodos, getTodosLoading, (todos, isLoading) =&gt; todos.filter(todo =&gt; !todo.isCompleted),)Styled componentsAllow us to define styles inside our JavaScript filesSee CH06 in the example bundlenpm install styled-componentsimport styled from 'styled-components';const BigRedText = styled.div` font-size: 48px; color: #ff0000;`;Can now be used like any other component&lt;BigRedText&gt;I'm a Styled-Component&lt;/BigRedText&gt;In addition to styled.div can also use styled.h1 styled.button styled.(and any other html element name here)This now means that we can pass props into BigRedText eg.&lt;BigRedText createdDays={todo.numberOfDays}&gt;&lt;/BigRedText&gt;Now the style changes based on the numberOfDaysconst BigRedText = styled.div` font-size: ${props =&gt; (props.createdDays &gt; 4 ? '48px' : '96px')}; color: #ff0000;`;You can also Inherit stylesconst BigRedTextWithWarning = styled(BigRedText)` color: #ff0000; font-size: x-large;`;TestingSee CH07 in the example bundleSetupnpm install --save-dev mocha chainpm install --save-dev @babel/registernpm install --save-dev sinon node-fetch fetch-mockModify package.json\"test\": \"mocha \\\"src/**/*.test.js\\\" --require @babel/register --recursive\"npm run test to run test suite.Testing ReducersCreate tests folder, Create reducers.test.jsimport { expect } from 'chai';import { todos } from '../reducers';describe('The todos reducer', () =&gt; { it('Adds a new todo where CREATE_TODO action is received', () =&gt; { const fakeTodo = { text: 'hello', isCompleted: false }; const fakeAction = { type: 'CREATE_TODO', payload: { todo: fakeTodo, }, }; const originalState = { isLoading: false, data: [] }; const expected = { isLoading: false, data: [fakeTodo], }; const actual = todos(originalState, fakeAction); expect(actual).to.deep.equal(expected); });});Testing Redux ThunksIn tests folder, Create thunks.test.jsimport 'node-fetch';import 'fetchMock' from 'fetch-mock';import { expect } from 'chai';import sinon from 'sinon';import { loadTodos } from '../thunks';describe('The loadTodos thunk', () =&gt; { it('Dispatches the correct actions in the success scenario', async () =&gt; { const fakeDispatch = sinon.spy(); const fakeTodos = [{ text: '1'}, { text: '2' }]; fetchMock.get('http://localhost:8080/todos', fakeTodos); const expectedFirstAction = { type: 'LOAD_TODOS_IN_PROGRESS' }; const expectedSecondAction = { type: 'LOAD_TODOS_SUCCESS', payload: { todos: fakeTodos, } }; await loadTodos()(fakeDispatch); expect(fakeDispatch.getCall(0).args[0]).to.deep.equal(expectedFirstAction); expect(fakeDispatch.getCall(1).args[0]).to.deep.equal(expectedSecondAction); fetchMock.reset(); // Restore to original state });});Testing SelectorsIn tests folder, Create selectors.test.jsimport { expect } from 'chai';import { getCompletedTodos } from '../selectors';describe('The getCompletedTodos selector', () =&gt; { it('Returns only completed todos', () =&gt; { const fakeTodos = [{ text: 'Say hello', isCompleted: true }, { text: 'Say Goodbye', isCompleted: false }, { text: 'Climb Mount Everest', isCompleted: false }]; const expected = [{ text: 'Say hello', isCompleted: true }]; /// Note the .resultFunc to get the last function which you're testing const actual = getCompletedTodos.resultFunc(fakeTodos); expect(actual).to.deep.equal(expected); });});Testing Styled ComponentsWe won’t be testing the style output, what we can test is the function which determines the style output.Just extract into an export function and test that.const BigRedText = styled.div` font-size: ${props =&gt; (props.createdDays &gt; 4 ? '48px' : '96px')}; color: #ff0000;`;Convert toexport const getStyleForCreated = (days) =&gt; (days &gt; 4 ? '48px' : '96px');const BigRedText = styled.div` font-size: ${props =&gt; getStyleForCreated(props.createdDays)}; color: #ff0000;`;In tests folder, Create COMPONENT-NAME.test.jsimport { expect } from 'chai';import { getStyleForCreated } from '../COMPONENT-NAME';describe('getStyleForCreated', () =&gt; { it('Returns 48px when days &gt; 4', () =&gt; { const actual = getStyleForCreated(10); expect(actual).to.equal('48px'); }); it('Returns 96px when days &lt;= 4', () =&gt; { const actual = getStyleForCreated(3); expect(actual).to.equal('96px'); });});" }, { "title": "Using Centos 8 Stream as a self hosted build agent", "url": "/posts/centos8-devops-buildagent/", "categories": "linux", "tags": "centos, centos8", "date": "2022-06-01 18:12:00 +0100", "snippet": "Install dependenciesImportant: Boot using the root accountdnf update -ydnf install git -yrpm -Uvh https://packages.microsoft.com/config/rhel/7/packages-microsoft-prod.rpmdnf install dotnet-sdk-2.1 -y# Update package reference, otherwise you'll get the 6.0 RC versionrpm -Uvh https://packages.microsoft.com/config/centos/8/packages-microsoft-prod.rpmecho 'priority=50' | sudo tee -a /etc/yum.repos.d/microsoft-prod.repodnf install dotnet-sdk-6.0 -ydnf install dotnet-sdk-7.0 -ydnf install aspnetcore-runtime-7.0 -ydnf install dotnet-runtime-7.0 -ydnf module enable nodejs:18dnf install nodejs -y# Add Mono Repodnf config-manager --add-repo https://download.mono-project.com/repo/centos8-stable.repodnf install mono-complete -yyum install -y powershellBuild AgentAdd build useruseradd buildagentpasswd buildagentusermod -aG wheel buildagentDownload agentMicrosoft articlewget https://vstsagentpackage.azureedge.net/agent/2.204.0/vsts-agent-linux-x64-2.204.0.tar.gzmkdir /buildcd /buildtar zxvf ~/vsts-agent-linux-x64-2.204.0.tar.gzcd ..chown -R buildagent:buildagent ./buildConfigure agentsu -l buildagentcd /build./config.shRun agent to test./run.shRun agent as a serviceLogout of buildagent accountexitcd /build./svc.sh install./svc.sh startInstall Chrome browser for Web UI testingStack overflow linkwget https://chromedriver.storage.googleapis.com/100.0.4896.20/chromedriver_linux64.zipmkdir /chromecd /chromeunzip ~/chromedriver_linux64.zip./chromedriver --versioncd ~wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpmsudo yum install google-chrome-stable_current_x86_64.rpmcd /nascd build./svc.sh stop./svc.sh startPotential errorsThe user’s home directory could not be determined. Set the ‘DOTNET_CLI_HOME’ environment variable to specify the directory to use.SolutionAdd Environment=DOTNET_CLI_HOME=/tmp to the service file automatically created.systemctl daemon-reload./svc.sh stop./svc.sh start" }, { "title": "Architectural design patterns", "url": "/posts/architectural-design-patterns/", "categories": "reading", "tags": "design-patterns", "date": "2022-05-23 18:12:00 +0100", "snippet": "Read Microsoft Cloud Design PatternsAmbassador patternCreate helper services that send network requests on behalf of a consumer service or application. An ambassador service can be thought of as an out-of-process proxy that is co-located with the client.Anti-corruption layerImplement a façade or adapter layer between different subsystems that don’t share the same semantics. This layer translates requests that one subsystem makes to the other subsystem. Use this pattern to ensure that an application’s design is not limited by dependencies on outside subsystems. This pattern was first described by Eric Evans in Domain-Driven Design.Asynchronous Request-ReplyDecouple backend processing from a frontend host, where backend processing needs to be asynchronous, but the frontend still needs a clear response.Backends for FrontendsCreate separate backend services to be consumed by specific frontend applications or interfaces. This pattern is useful when you want to avoid customizing a single backend for multiple interfaces. This pattern was first described by Sam Newman.BulkheadThe Bulkhead pattern is a type of application design that is tolerant of failure. In a bulkhead architecture, elements of an application are isolated into pools so that if one fails, the others will continue to function. It’s named after the sectioned partitions (bulkheads) of a ship’s hull. If the hull of a ship is compromised, only the damaged section fills with water, which prevents the ship from sinking.Cache-AsideLoad data on demand into a cache from a data store. This can improve performance and also helps to maintain consistency between data held in the cache and data in the underlying data store.ChoreographyHave each component of the system participate in the decision-making process about the workflow of a business transaction, instead of relying on a central point of control.Circuit BreakerHandle faults that might take a variable amount of time to recover from, when connecting to a remote service or resource. This can improve the stability and resiliency of an application.Claim CheckSplit a large message into a claim check and a payload. Send the claim check to the messaging platform and store the payload to an external service. This pattern allows large messages to be processed, while protecting the message bus and the client from being overwhelmed or slowed down. This pattern also helps to reduce costs, as storage is usually cheaper than resource units used by the messaging platform.This pattern is also known as Reference-Based Messaging, and was originally described in the book Enterprise Integration Patterns, by Gregor Hohpe and Bobby Woolf.Compensating TransactionUndo the work performed by a series of steps, which together define an eventually consistent operation, if one or more of the steps fail. Operations that follow the eventual consistency model are commonly found in cloud-hosted applications that implement complex business processes and workflows.Competing ConsumersEnable multiple concurrent consumers to process messages received on the same messaging channel. With multiple concurrent consumers, a system can process multiple messages concurrently to optimize throughput, to improve scalability and availability, and to balance the workload.Compute Resource ConsolidationConsolidate multiple tasks or operations into a single computational unit. This can increase compute resource utilization, and reduce the costs and management overhead associated with performing compute processing in cloud-hosted applications.CQRSCQRS stands for Command and Query Responsibility Segregation, a pattern that separates read and update operations for a data store. Implementing CQRS in your application can maximize its performance, scalability, and security. The flexibility created by migrating to CQRS allows a system to better evolve over time and prevents update commands from causing merge conflicts at the domain level.Deployment StampsThe deployment stamp pattern involves provisioning, managing, and monitoring a heterogeneous group of resources to host and operate multiple workloads or tenants. Each individual copy is called a stamp, or sometimes a service unit or scale unit. In a multi-tenant environment, every stamp or scale unit can serve a predefined number of tenants. Multiple stamps can be deployed to scale the solution almost linearly and serve an increasing number of tenants. This approach can improve the scalability of your solution, allow you to deploy instances across multiple regions, and separate your customer data.Edge Workload ConfigurationThe great variety of systems and devices on the shop floor can make workload configuration a difficult problem. This article provides approaches to solving it.Event sourcing patternInstead of storing just the current state of the data in a domain, use an append-only store to record the full series of actions taken on that data. The store acts as the system of record and can be used to materialize the domain objects. This can simplify tasks in complex domains, by avoiding the need to synchronize the data model and the business domain, while improving performance, scalability, and responsiveness. It can also provide consistency for transactional data, and maintain full audit trails and history that can enable compensating actions.External Configuration StoreMove configuration information out of the application deployment package to a centralized location. This can provide opportunities for easier management and control of configuration data, and for sharing configuration data across applications and application instances.Federated IdentityDelegate authentication to an external identity provider. This can simplify development, minimize the requirement for user administration, and improve the user experience of the application.GatekeeperProtect applications and services by using a dedicated host instance that acts as a broker between clients and the application or service, validates and sanitizes requests, and passes requests and data between them. This can provide an additional layer of security, and limit the attack surface of the system.Gateway AggregationUse a gateway to aggregate multiple individual requests into a single request. This pattern is useful when a client must make multiple calls to different backend systems to perform an operation.Gateway OffloadingOffload shared or specialized service functionality to a gateway proxy. This pattern can simplify application development by moving shared service functionality, such as the use of SSL certificates, from other parts of the application into the gateway.Gateway RoutingRoute requests to multiple services using a single endpoint. This pattern is useful when you wish to expose multiple services on a single endpoint and route to the appropriate service based on the request.GeodeThe Geode pattern involves deploying a collection of backend services into a set of geographical nodes, each of which can service any request for any client in any region. This pattern allows serving requests in an active-active style, improving latency and increasing availability by distributing request processing around the globe.Health Endpoint monitoringImplement functional checks in an application that external tools can access through exposed endpoints at regular intervals. This can help to verify that applications and services are performing correctly.Index TableCreate indexes over the fields in data stores that are frequently referenced by queries. This pattern can improve query performance by allowing applications to more quickly locate the data to retrieve from a data store.Leader ElectionCoordinate the actions performed by a collection of collaborating instances in a distributed application by electing one instance as the leader that assumes responsibility for managing the others. This can help to ensure that instances don’t conflict with each other, cause contention for shared resources, or inadvertently interfere with the work that other instances are performing.Materialized ViewGenerate prepopulated views over the data in one or more data stores when the data isn’t ideally formatted for required query operations. This can help support efficient querying and data extraction, and improve application performance.Pipes and FiltersDecompose a task that performs complex processing into a series of separate elements that can be reused. This can improve performance, scalability, and reusability by allowing task elements that perform the processing to be deployed and scaled independently.Priority QueuePrioritize requests sent to services so that requests with a higher priority are received and processed more quickly than those with a lower priority. This pattern is useful in applications that offer different service level guarantees to individual clients.Publisher/SubscriberEnable an application to announce events to multiple interested consumers asynchronously, without coupling the senders to the receivers.Queue based load levelingUse a queue that acts as a buffer between a task and a service it invokes in order to smooth intermittent heavy loads that can cause the service to fail or the task to time out. This can help to minimize the impact of peaks in demand on availability and responsiveness for both the task and the service.Rate limitingMany services use a throttling pattern to control the resources they consume, imposing limits on the rate at which other applications or services can access them. You can use a rate limiting pattern to help you avoid or minimize throttling errors related to these throttling limits and to help you more accurately predict throughput.RetryEnable an application to handle transient failures when it tries to connect to a service or network resource, by transparently retrying a failed operation. This can improve the stability of the application.Saga - Example codeThe Saga design pattern is a way to manage data consistency across microservices in distributed transaction scenarios. A saga is a sequence of transactions that updates each service and publishes a message or event to trigger the next transaction step. If a step fails, the saga executes compensating transactions that counteract the preceding transactions.Scheduler Agent supervisorCoordinate a set of distributed actions as a single operation. If any of the actions fail, try to handle the failures transparently, or else undo the work that was performed, so the entire operation succeeds or fails as a whole. This can add resiliency to a distributed system, by enabling it to recover and retry actions that fail due to transient exceptions, long-lasting faults, and process failures.Sequential convoyProcess a set of related messages in a defined order, without blocking processing of other groups of messages.ShardingDivide a data store into a set of horizontal partitions or shards. This can improve scalability when storing and accessing large volumes of data.SidecarDeploy components of an application into a separate process or container to provide isolation and encapsulation. This pattern can also enable applications to be composed of heterogeneous components and technologies.Static content hostingDeploy static content to a cloud-based storage service that can deliver them directly to the client. This can reduce the need for potentially expensive compute instances.Strangler figIncrementally migrate a legacy system by gradually replacing specific pieces of functionality with new applications and services. As features from the legacy system are replaced, the new system eventually replaces all of the old system’s features, strangling the old system and allowing you to decommission it.ThrottlingControl the consumption of resources used by an instance of an application, an individual tenant, or an entire service. This can allow the system to continue to function and meet service level agreements, even when an increase in demand places an extreme load on resources.Valet keyUse a token that provides clients with restricted direct access to a specific resource, in order to offload data transfer from the application. This is particularly useful in applications that use cloud-hosted storage systems or queues, and can minimize cost and maximize scalability and performance." }, { "title": "Kafka notes", "url": "/posts/kafka-commands/", "categories": "linux", "tags": "c#, kafka", "date": "2022-05-18 12:34:00 +0100", "snippet": "KafkaScripts directory/opt/bitnami/kafka/binLogging into the Kafka Containerdocker exec -it kafka-broker /bin/bashNavigate to the Kafka Scripts directorycd /opt/bitnami/kafka/binCreating new Topics./kafka-topics.sh \\ --bootstrap-server localhost:9092 \\ --create \\ --topic kafka.learning.tweets \\ --partitions 1 \\ --replication-factor 1./kafka-topics.sh \\ --bootstrap-server localhost:9092 \\ --create \\ --topic kafka.learning.alerts \\ --partitions 1 \\ --replication-factor 1Listing Topics./kafka-topics.sh \\ --bootstrap-server localhost:9092 \\ --listGetting details about a Topic./kafka-topics.sh \\ --bootstrap-server localhost:9092 \\ --describePublishing Messages to Topics./kafka-console-producer.sh \\ --bootstrap-server localhost:9092 \\ --topic kafka.learning.tweetsConsuming Messages from Topics./kafka-console-consumer.sh \\ --bootstrap-server localhost:29092 \\ --topic kafka.learning.tweets \\ --from-beginningDeleting Topics./kafka-topics.sh \\ --bootstrap-server localhost:29092 \\ --delete \\ --topic kafka.learning.alertsCreate a Topic with multiple partitions./kafka-topics.sh \\ --bootstrap-server localhost:9092 \\ --create \\ --topic kafka.learning.orders \\ --partitions 3 \\ --replication-factor 1Check topic partitioning./kafka-topics.sh \\ --bootstrap-server localhost:9092 \\ --topic kafka.learning.orders \\ --describePublishing Messages to Topics with keys./kafka-console-producer.sh \\ --bootstrap-server localhost:29092 \\ --property \"parse.key=true\" \\ --property \"key.separator=:\" \\ --topic kafka.learning.ordersConsume messages using a consumer group./kafka-console-consumer.sh \\ --bootstrap-server localhost:29092 \\ --topic kafka.learning.orders \\ --group test-consumer-group \\ --property print.key=true \\ --property key.separator=\" = \" \\ --from-beginningCheck current status of offsets./kafka-consumer-groups.sh \\ --bootstrap-server localhost:29092 \\ --describe \\ --all-groupsDockerfileversion: '2'services:#Zookeeper Service. zookeeper: image: 'bitnami/zookeeper:latest' restart: \"no\" ports: - '2181:2181' volumes: - \"zookeeper_data:/bitnami\" environment: - ALLOW_ANONYMOUS_LOGIN=yes container_name: zookeeper#Kafka Service kafka: image: 'bitnami/kafka:latest' restart: \"no\" ports: - '9092:9092' - '29092:29092' volumes: - \"kafka_data:/bitnami\" environment: - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT - KAFKA_CFG_LISTENERS=INTERNAL://:29092,EXTERNAL://:9092 - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:29092,EXTERNAL://docker-pve.localdomain:9092 - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181 - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL - ALLOW_PLAINTEXT_LISTENER=yes container_name: kafka-broker depends_on: - \"zookeeper\" volumes: zookeeper_data: driver: local kafka_data: driver: localErrorsConnection problems thrd:localhost:9092/1001]: localhost:9092/1001: Connect to ipv4#127.0.0.1:9092 failed: Unknown error (after 2047ms in state CONNECT) The advertised broker address is set to localhost, needs docker host DNS address Update this line to contain docker address instead, example, KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:29092,EXTERNAL://docker-pve.localdomain:9092C# Sample codeInstall-Package 'Confluent.Kafka'public static async Task PublishAsync(){ var config = new ProducerConfig { BootstrapServers = \"docker-pve.localdomain:9092\", ClientId = Dns.GetHostName() }; using (var producer = new ProducerBuilder&lt;Null, string&gt;(config).Build()) { for (var i = 0; i &lt; 2000; i++) { await producer.ProduceAsync(\"weblogs\", new Message&lt;Null, string&gt; { Value = $\"hello world - {i}\" }).ContinueWith(task =&gt; { if (task.IsFaulted) { } else { Console.WriteLine($\"Wrote to offset: {task.Result.Offset}\"); } }); } }}public static void ConsumeAsync(){ var config = new ConsumerConfig { BootstrapServers = \"docker-pve.localdomain:9092\", GroupId = \"foo\", AutoOffsetReset = AutoOffsetReset.Earliest }; bool cancelled = false; using (var consumer = new ConsumerBuilder&lt;Ignore, string&gt;(config).Build()) { consumer.Subscribe(\"weblogs\"); while (!cancelled) { var result = consumer.Consume(100); if (result != null) { var msg = result.Message.Value; Console.WriteLine(msg); } } consumer.Close(); }}" }, { "title": "Mocking Begin/End Async API", "url": "/posts/moq-task-factory-fromasync/", "categories": ".net", "tags": "c#, testing, moq, async-pattern", "date": "2022-05-17 19:36:00 +0100", "snippet": "MoqExamplevar request = new ReceiveMessageRequest();var msg = await Task&lt;ReceiveMessageResponse&gt;.Factory.FromAsync(queue.BeginReceiveMessage, queue.EndReceiveMessage, request, null);Testvar receiveMessageAsyncResult = new Mock&lt;IAsyncResult&gt;();_queue.Setup(x =&gt; x.BeginReceiveMessage(It.IsAny&lt;ReceiveMessageRequest&gt;(), It.IsAny&lt;AsyncCallback&gt;(), It.IsAny&lt;object&gt;())) .Returns(receiveMessageAsyncResult.Object) .Callback((ReceiveMessageRequest rmr, AsyncCallback cb, object state) =&gt; { receiveMessageAsyncResult.Setup(x =&gt; x.AsyncState).Returns(state); cb(receiveMessageAsyncResult.Object); });_queue.Setup(x =&gt; x.EndReceiveMessage(It.IsAny&lt;IAsyncResult&gt;())).Returns(() =&gt;{ if (messageCount &gt; 0) { throw new MessageNotExistException(\"No more messages\"); } messageCount++; return new ReceiveMessageResponse { Message = new Message { Body = \"SGVsbG8gV29ybGQ=\", // Hello World ReceiptHandle = \"12345\" } };});" }, { "title": "How to disable the smiley keyboard", "url": "/posts/disable-smiley-keyboard/", "categories": "mac", "tags": "misc", "date": "2022-05-14 23:16:00 +0100", "snippet": "I keep catching the fn or globe button on the mac keyboard and the smiley on-screen keyboard pops up, really annoying!Disabling this shortcut can be accomplished by opening the System Preferences and navigating to the Keyboard panel.From within the Keyboard tab, look for the label that reads Press globe icon to. It likely reads Show Emoji &amp; Symbols. Click on the dropdown and choose Do Nothing to disable the emoji shortcut." }, { "title": "Learning Rust", "url": "/posts/learning-rust/", "categories": "learning", "tags": "rust", "date": "2022-04-23 08:58:00 +0100", "snippet": " Rust for Beginners - Watched all 35 videos The book Rust and WebAssembly Rust Playground IDE Rust Cookbook of getting started snippets" }, { "title": "nginx config", "url": "/posts/nginx-config/", "categories": "linux", "tags": "nginx", "date": "2021-12-21 13:40:00 +0000", "snippet": "Nginx.conf# For more information on configuration, see:# * Official English Documentation: http://nginx.org/en/docs/# * Official Russian Documentation: http://nginx.org/ru/docs/user nginx;worker_processes auto;error_log /var/log/nginx/error.log;pid /run/nginx.pid;# Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.include /usr/share/nginx/modules/*.conf;events { worker_connections 1024;}http { log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; error_log /var/log/nginx/error.log; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; # Load modular configuration files from the /etc/nginx/conf.d directory. # See http://nginx.org/en/docs/ngx_core_module.html#include # for more information. include /etc/nginx/conf.d/*.conf; include /nas/nginx/sites-available/*.conf;}Default.site.conf server { listen 80 default_server; listen [::]:80 default_server; server_name {server domain name}; root /usr/share/nginx/html; rewrite ^\\/redirect\\/mobile-app$ https://a.app.qq.com/o/simple.jsp?pkgname=package.names redirect; rewrite ^\\/redirect\\/hs241-install-video$ /video-library redirect; add_header X-XSS-Protection '1; mode=block'; add_header X-Content-Type-Options 'nosniff'; add_header Strict-Transport-Security 'max-age=31536000; includeSubDomains'; add_header X-Frame-Options 'SAMEORIGIN'; add_header Report-To '{\"group\":\"default\",\"max_age\":10886400,\"endpoints\":[{\"url\":\"https://7pz13sb7.uriports.com/reports\"}],\"include_subdomains\":true}'; add_header NEL '{\"report_to\":\"default\",\"max_age\":2592000,\"include_subdomains\":true,\"failure_fraction\":1.0}'; add_header Content-Security-Policy \"default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval' assets.server.com js.hs-scripts.com js.hsforms.net forms.hsforms.com hm.baidu.com js.hscollectedforms.net js.usemessages.com js.hs-banner.com js.hs-analytics.net js.hsleadflows.net *.alipayobjects.com https://*.hotjar.com https://*.hotjar.io *.baidu.com www.googletagmanager.com www.google-analytics.com fe-resource.cdn.bcebos.com ; script-src-elem 'self' 'unsafe-inline' 'unsafe-hashes' 'unsafe-eval' assets.server.com js.hs-scripts.com js.hsleadflows.net *.baidu.com sofire.bdstatic.com js.hscollectedforms.net js.usemessages.com *.hs-analytics.net js.hs-banner.com js.hsforms.net forms.hsforms.com static.hotjar.com script.hotjar.com www.googletagmanager.com *.google-analytics.com www.google.com www.gstatic.com fe-resource.cdn.bcebos.com; script-src-attr 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline' assets.server.com fonts.googleapis.com; style-src-elem 'self' fonts.googleapis.com 'unsafe-inline' assets.server.com sgoutong.baidu.com; style-src-attr 'self' 'unsafe-inline'; img-src 'self' data: *.baidu.com *.hubspot.com forms.hsforms.com f.hubspotusercontent00.net android-webview-video-poster: f.hubspotusercontent10.net *.server.com https://*.hotjar.com https://*.hotjar.io www.google-analytics.com www.googletagmanager.com www.gstatic.com exceptions.hs-embed-reporting.com; font-src 'self' fonts.gstatic.com *.server.com https://*.hotjar.com https://*.hotjar.io; connect-src 'self' *.hubspot.com *.baidu.com forms.hsforms.com https://*.hotjar.com:* https://*.hotjar.io wss://*.hotjar.com www.google-analytics.com videojet.fact-finder.co.uk; media-src 'self' vod.server.com; object-src 'self'; child-src; frame-src 'self' forms.hsforms.com *.hubspot.com https://*.hotjar.com https://*.hotjar.io www.google.com; worker-src; frame-ancestors 'self' app.hubspot.com *.baidu.com; form-action 'self' http://*.server.com forms.hsforms.com forms.hubspot.com *.alipay.com *.alipaydev.com; base-uri 'self'; manifest-src 'self'; report-uri https://7pz13sb7.uriports.com/reports/enforce; report-to default\"; # add_header Content-Security-Policy-Report-Only \"default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval' assets.server.com js.hs-scripts.com js.hsforms.net forms.hsforms.com hm.baidu.com js.hscollectedforms.net js.usemessages.com js.hs-banner.com js.hs-analytics.net *.alipayobjects.com www.google-analytics.com js.hsleadflows.net; script-src-elem 'self' 'unsafe-inline' 'unsafe-hashes' 'unsafe-eval' assets.server.com js.hs-scripts.com hm.baidu.com js.hscollectedforms.net js.usemessages.com *.hs-analytics.net js.hs-banner.com js.hsforms.net forms.hsforms.com; script-src-attr 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline' assets.server.com fonts.googleapis.com; style-src-elem 'self' 'unsafe-inline' assets.server.com; style-src-attr 'self' 'unsafe-inline'; img-src 'self' assets.server.com data: hm.baidu.com *.hubspot.com forms.hsforms.com android-webview-video-poster: f.hubspotusercontent10.net sgoutong.baidu.com; font-src 'self' assets.server.com; connect-src 'self' *.hubspot.com hm.baidu.com forms.hsforms.com; media-src 'self' vod.server.com; object-src 'self'; prefetch-src 'self'; child-src; frame-src 'self' forms.hsforms.com app.hubspot.com; worker-src; frame-ancestors 'self'; form-action 'self' http://www.server.com forms.hsforms.com openapi.alipay.com mclient.alipay.com; base-uri 'self'; manifest-src 'self'; plugin-types application/pdf; report-uri https://7pz13sb7.uriports.com/reports/report; report-to default\"; add_header Expect-CT 'max-age=86400,enforce,report-uri=\"https://7pz13sb7.uriports.com/reports/enforce\"'; add_header Referrer-Policy 'strict-origin-when-cross-origin'; add_header X-Permitted-Cross-Domain-Policies 'none'; # Increase max file upload to limit of kestrel client_max_body_size 28M; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { proxy_pass http://localhost:5001; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection keep-alive; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $http_x_forwarded_for; proxy_set_header X-Forwarded-Proto $http_x_forwarded_proto; proxy_cache_bypass $http_upgrade; proxy_buffering off; } error_page 404 /404.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } }# Settings for a TLS enabled server.# ----------------------------------------------------------------------# SSL Needed to run scheduled tasks - Do not remove or comment out # ---------------------------------------------------------------------- server { listen 443 ssl http2 default_server; listen [::]:443 ssl http2 default_server; server_name {server domain name}; root /usr/share/nginx/html; ssl_certificate \"/etc/pki/nginx/server.crt\"; ssl_certificate_key \"/etc/pki/nginx/STAR_server_com.key\"; ssl_protocols TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_ciphers \"EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH\"; ssl_ecdh_curve secp384r1; ssl_session_cache shared:SSL:10m; ssl_session_tickets off; add_header X-Frame-Options DENY; add_header X-Content-Type-Options nosniff; add_header X-Frame-Options \"SAMEORIGIN\"; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { proxy_pass http://localhost:5001; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection keep-alive; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Port $server_port; proxy_cache_bypass $http_upgrade; } error_page 404 /404.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } }" }, { "title": "Docker compose file", "url": "/posts/docker-compose/", "categories": "linux", "tags": "c#, docker", "date": "2021-12-05 14:20:00 +0000", "snippet": "At the root of the project create a file: docker-compose.ymlversion: '3'services: api: image: conference/api container_name: conference_api build: context: . ports: - 5000:80 environment: ASPNETCORE_ENVIRONMENT: Production depends_on: - postgres postgres: image: postgres:9.6.3 container_name: conference_db environment: POSTGRES_DB: conference POSTGRES_USER: conf_app POSTGRES_PASSWORD: docker ports: - 5432:5432 volumes: - ./db:/docker-entrypoint-initdb.dTo run the docker compose filedocker-compose upTo push your container to docker hubdocker tag {imageId} {username name}/{container name}:{tag name}To log into your docker accountdocker logindocker push {username}/{container name}:{tag name}" }, { "title": "Useful Docker commands", "url": "/posts/useful-docker-commands/", "categories": "linux", "tags": "docker", "date": "2021-12-05 14:10:00 +0000", "snippet": "Docker Versiondocker -vList Docker imagesdocker image listDownload an imagedocker pull nginx:1.13.8Remove docker imagedocker rmi {image id}Run an image and then interact with the command linedocker run -it nginx:1.13.8 /bin/bashExecute commands within an already running containerdocker exec -it containername /bin/bashList containers runningdocker container listList containers running or stoppeddocker container list -aStop a containerdocker stop {container id}Remove a containerdocker rm {container id}Copy files into a containerdocker cp /tmp/config.ini grafana:/usr/share/grafana/conf/docker cp /tmp/config.ini 1477326feb62:/usr/share/grafana/conf/" }, { "title": "To dockerize a visual studio project", "url": "/posts/how-to-dockerize-a-visual-studio-project/", "categories": "linux", "tags": "aspnet, docker", "date": "2021-12-05 13:13:00 +0000", "snippet": "If creating a new project, then Enable docker support during project creationOR Create a file in the project root called Dockerfile (no extension) Inside the fileFROM microsoft/aspnetcore-build:2.0 AS buildWORKDIR /buildCOPY . .RUN dotnet restoreRUN dotnet publish -c Release -o outputFROM microsoft/aspnetcore:2.0WORKDIR /appCOPY --from=build /build/output .ENTRYPOINT [\"dotnet\", \"ConferenceApp.dll\"]To build image (from project root)docker build -t conference/api .To remove the imagedocker system prune* All Stopped containers* All networks not used by at least one container* All dangling images* All build cacheTo run a docker imagedocker run -d —name {chosen name} {image name:tag}If an image has exited with a status code of other than 0, then it has not exited properly, perhaps there’s an errordocker logs {container name}" }, { "title": "Remote desktop and stepping though code using 'F11' key", "url": "/posts/remote-desktop-and-stepping-through-code/", "categories": "mac", "tags": "misc", "date": "2021-11-14 21:57:00 +0000", "snippet": "ProblemThe F11 key is commonly used during a debugging session, to step through lines of code. So you can imaging the suprise when one of your most used keys fails to work as expected and oddly only when connecting to the remote machine using a Remote desktop connection.The fixAfter alot of internet searching I came across this articleI had to un-map the F11 from showing the ‘desktop’ in System Preferences &gt; Keyboard &gt; shortcuts &gt; Show DeskTop (F11)" }, { "title": "Work items and branching strategy", "url": "/posts/work-items-branching-stratedgy/", "categories": "ways-of-working", "tags": "best-practice", "date": "2021-11-10 08:43:00 +0000", "snippet": "Work itemsUser StoryA user story should always belong to whoever requested the work to be completed (usually someone wearing the Product Owner metaphorical ‘hat’) - That said, it is not a requirement for it to be authored by them.It should include a clear and agreed acceptance criteria, that once achieved completes that story. If it is deemed as too large (it has story points greater than 8 - see Sizing guide), then it should be split into multiple stories and include a feature flag strategy so that it can still be deployed into the Live environment safely knowing that it will not function until the feature flag has been enabled.TasksThe developer should create Tasks on the User Story that they feel are necessary to complete that User Story.Branching strategyA very successful branching model which was conceived more than 10 years ago and has been used by many software departments, was first published on nvie.com, later it was made available and called Git Flow.In various companies I have worked, I have implemented this and subsequently integrated it into deployment pipelines. This requires branch names to be formatted in the following way feature/{user story number}-title-of-the-user-story task/{task number}-title-of-the-taskAs per the Git Flow model, feature branches should have the parent branch set to dev and task branches should have the parent branch set to their respective feature branch.Having the user story / task number in the branch name, makes it easier for someone to cross check stale branches to validate if the branch is no longer required.Pull request reviews are not required when merging task branches into feature branches. However they are necessary when merging the feature branch into the dev branch.Once the User story / Feature is deemed complete then it should be merged into the dev branch via the Pull Request procedure.Additional notes on branchingFEATURE branchesThis branch type contains your current work stream. When you have completed your changes, you may execute a Build pipeline step. This will perform a build, once the build completes successfully then you are able to deploy to a test.DEV branchThis branch only contains completed features aka user stories. This may have features considered ready for production but the timing may not be right eg. CHANGE FREEZE.MAIN aka MASTER branchThis branch only contains features deemed to be complete and is as close to what is running in the PRODUCTION environment as possible. Also note, this may contain features that are in the process of being sent to a PRODUCTION environment however the window for this is very narrow (10 minutes) and so can be considered as to what is running in the production environment." }, { "title": "RaspberryPi NUT server with QNAP integration", "url": "/posts/raspberrypi-nut-server-with-qnap-integration/", "categories": "linux", "tags": "nut-server, raspberrypi", "date": "2021-08-14 13:23:00 +0100", "snippet": "Referenceshttps://www.howtoraspberry.com/2020/11/how-to-monitor-ups-with-raspberry-pihttps://www.howtoraspberry.com/2021/05/how-to-configure-an-orderly-shutdown/https://blog.fosketts.net/2015/06/03/automated-ups-monitoring-for-vsphere-with-nut-and-raspberry-pi-cheap/https://www.reddit.com/r/homelab/comments/5ssb5h/ups_server_on_raspberry_pi/https://wiki.ledhed.net/index.php?title=Raspberry_Pi_NUT_ServerFor detailed NUT config and low battery warningsStarting with a Raspberry Pi new imagesudo raspi-config enable ssh change hostname to upsInstall Nut toolssudo apt-get updatesudo apt-get upgradesudo apt-get update &amp;&amp; sudo apt-get install nut nut-client nut-serverEdit /etc/nut/ups.conf and add the snippet below to the end of the file[qnapups]driver = usbhid-upsport = autodesc = \"CyberPower AVR UPS\"pollinterval = 15override.battery.charge.low = 30override.battery.charge.warning = 5override.battery.runtime.low = 180Edit /etc/nut/upsd.conf and add the snippet below to the end of the fileMAXAGE 25Edit /etc/nut/upsd.users and add the snippet below to the end of the file[admin]password = 12345upsmon masterinstcmds = ALLactions = SETEdit /etc/nut/upsmon.conf and add the snippet below to the end of the fileLISTEN {current-ip-address} 3493MONITOR qnapups@localhost 1 admin 123456 masterAlso in the same file above setDEADTIME 25Edit /etc/nut/nut.conf and set MODE valueMODE=netserverReboot!Install Webserversudo apt install apache2 nut-cgiEdit /etc/nut/hosts.conf and add the snippet below to the end of the fileMONITOR qnapups@localhost \"Server UPS\"/etc/nut $ sudo a2enmod cgisystemctl restart apache2Edit /etc/nut/upsset.conf and uncomment (remove #)### I_HAVE_SECURED_MY_CGI_DIRECTORYBrowse tohttp://ups.localdomain/cgi-bin/nut/upsset.cgiUSR: adminPWD: 123456http://ups.localdomain/cgi-bin/nut/upsstats.cgiQnap as UPS Slave to Raspberry Pi NUT serverhttps://forum.qnap.com/viewtopic.php?t=60166 your upsname must be named qnapups, and user “admin” with password “123456” must be allowed to connect.The user/password pair can be changed manually on the QNAP. The UPS name can not be changed (at least I was not able to find way how to change it) but you can change the username/password manually in /etc/config/ups/upsmon.confTo generate data as JSON, exported as JSON object in webpageupsstats-single.html file contents&lt;!-- upsstats template file --&gt;&lt;!--\tThis is upsstats-single.html, a template for monitoring a single\thost. This mode is selected by adding \"host=&lt;host&gt;\" to the\tupsstats.cgi URL.\tSuch URLs are generated automatically when using the HOSTLINK\tcommand.\tSee upsstats.html(5) for more information on template files.--&gt;&lt;!-- change this to TEMPF if you don't like Celsius. --&gt;@TEMPC@@UPSSTATSPATH upsstats.cgi@@UPSIMAGEPATH upsimage.cgi@&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\t\"http://www.w3.org/TR/REC-html40/loose.dtd\"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"&gt;@REFRESH@&lt;title&gt;@HOSTDESC@ : @VAR ups.model@ on @HOST@&lt;/title&gt;&lt;!-- LINK REL=\"stylesheet\" TYPE=\"text/css\" HREF=\"http://localhost/nut/nut.css\" / --&gt;&lt;/head&gt;&lt;body BGCOLOR=\"#808080\" TEXT=\"#00FC00\" LINK=\"#0000EE\" VLINK=\"#551A8B\"&gt;&lt;table BORDER=\"1\" ALIGN=\"CENTER\" CELLSPACING=\"0\" CELLPADDING=\"10\" BGCOLOR=\"#000000\"&gt;&lt;tr&gt;&lt;th COLSPAN=\"20\"&gt;Network UPS Tools upsstats @VERSION@ - @HOSTDESC@ - @VAR ups.model@ on @HOST@&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th&gt;@DATE %a %b %d %X %Z %Y@&lt;/th&gt;@IFSUPP ambient.temperature@&lt;th&gt;Ambient&lt;/th&gt;@ELSE@@IFSUPP ambient.humidity@&lt;th&gt;Ambient&lt;/th&gt;@ENDIF@&lt;th&gt;Battery&lt;/th&gt;&lt;th&gt;Input&lt;/th&gt;&lt;th&gt;Output&lt;/th&gt;&lt;th&gt;Load&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td BGCOLOR=\"#000000\" VALIGN=\"TOP\"&gt;&lt;table BORDER=\"0\"&gt;\t&lt;!-- table 2 --&gt;&lt;tr&gt;&lt;th ALIGN=\"RIGHT\"&gt;UPS Model:&lt;/th&gt;&lt;td&gt;@VAR ups.model@&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th ALIGN=\"RIGHT\"&gt;Status:&lt;/th&gt;&lt;td&gt;@STATUS@&lt;/td&gt;&lt;/tr&gt;@IFSUPP battery.runtime@&lt;tr&gt;&lt;th ALIGN=\"RIGHT\"&gt;Runtime:&lt;/th&gt;&lt;td&gt;@RUNTIME@&lt;/td&gt;&lt;/tr&gt;@ENDIF@@IFSUPP ups.temperature@&lt;tr&gt;&lt;th ALIGN=\"RIGHT\"&gt;UPS temp:&lt;/th&gt;&lt;td&gt;@UPSTEMP@ @DEGREES@&lt;/td&gt;&lt;/tr&gt;@ENDIF@@IFSUPP battery.voltage@&lt;tr&gt;&lt;th ALIGN=\"RIGHT\"&gt;Battery: &lt;/th&gt;&lt;td&gt;@VAR battery.voltage@ V@IFSUPP battery.current@, @VAR battery.current@ A&lt;/td&gt;@ENDIF@&lt;tr&gt;&lt;th VALIGN=\"TOP\" ALIGN=\"RIGHT\"&gt;Input: &lt;/th&gt;&lt;td&gt;@IFSUPP input.L2-L3.voltage@@VAR input.L1-L2.voltage@ V&lt;br&gt;@VAR input.L2-L3.voltage@ V&lt;br&gt;@VAR input.L3-L1.voltage@ V&lt;br&gt;&lt;/td&gt;&lt;/tr&gt;@ELSE@@IFSUPP input.L2-N.voltage@@VAR input.L1-N.voltage@ V&lt;br&gt;@VAR input.L2-N.voltage@ V&lt;br&gt;@VAR input.L3-N.voltage@ V&lt;br&gt;&lt;/td&gt;&lt;/tr&gt;@ELSE@@IFSUPP input.voltage@@VAR input.voltage@ V&lt;br&gt;&lt;/td&gt;&lt;/tr&gt;@ENDIF@@IFSUPP input.L2.current@&lt;tr&gt;&lt;th&gt;&lt;td&gt;@VAR input.L1.current@ A&lt;br&gt;@VAR input.L2.current@ A&lt;br&gt;@VAR input.L3.current@ A&lt;br&gt;&lt;/td&gt;&lt;/tr&gt;@ELSE@@IFSUPP input.current@&lt;tr&gt;&lt;th&gt;&lt;td&gt;@VAR input.current@ A&lt;/td&gt;&lt;/tr&gt;@ENDIF@@IFSUPP input.frequency@&lt;tr&gt;&lt;th&gt;&lt;td&gt;@VAR input.frequency@ Hz&lt;/td&gt;&lt;/tr&gt;@ENDIF@&lt;tr&gt;&lt;th VALIGN=\"TOP\" ALIGN=\"RIGHT\"&gt;Output: &lt;/th&gt;&lt;td&gt;@IFSUPP output.L2-L3.voltage@@VAR output.L1-L2.voltage@ V&lt;br&gt;@VAR output.L2-L3.voltage@ V&lt;br&gt;@VAR output.L3-L1.voltage@ V&lt;br&gt;&lt;/td&gt;&lt;/tr&gt;@ELSE@@IFSUPP output.L2-N.voltage@@VAR output.L1-N.voltage@ V&lt;br&gt;@VAR output.L2-N.voltage@ V&lt;br&gt;@VAR output.L3-N.voltage@ V&lt;br&gt;&lt;/td&gt;&lt;/tr&gt;@ELSE@@IFSUPP output.voltage@@VAR output.voltage@ V&lt;/td&gt;&lt;/tr&gt;@ENDIF@@IFSUPP output.L2.current@&lt;tr&gt;&lt;th&gt;&lt;td&gt;@VAR output.L1.current@ A&lt;br&gt;@VAR output.L2.current@ A&lt;br&gt;@VAR output.L3.current@ A&lt;br&gt;&lt;/td&gt;&lt;/tr&gt;@ELSE@@IFSUPP output.current@&lt;tr&gt;&lt;th&gt;&lt;td&gt;@VAR output.current@ A&lt;/td&gt;&lt;/tr&gt;@ENDIF@@IFSUPP output.frequency@&lt;tr&gt;&lt;th&gt;&lt;td&gt;@VAR output.frequency@ Hz&lt;/td&gt;&lt;/tr&gt;@ENDIF@&lt;/table&gt;\t\t&lt;!-- table 2 --&gt;&lt;/td&gt;@IFSUPP ambient.temperature@@IFSUPP ambient.humidity@&lt;td ALIGN=\"CENTER\" VALIGN=\"TOP\" BGCOLOR=\"#000000\"&gt;&lt;table BORDER=\"0\"&gt;&lt;tr&gt;&lt;td ALIGN=\"CENTER\"&gt;Temperature&lt;br&gt;@IMG ambient.temperature tempmin=0 tempmax=50 width=90@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;Humidity&lt;br&gt;@IMG ambient.humidity width=90@&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;@ELSE@@IFSUPP ambient.temperature@&lt;td ALIGN=\"CENTER\" VALIGN=\"TOP\" BGCOLOR=\"#000000\"&gt;&lt;table BORDER=\"0\"&gt;&lt;tr&gt;&lt;td ALIGN=\"CENTER\"&gt;Temperature&lt;br&gt;@IMG ambient.temperature tempmin=0 tempmax=50@&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;@ELSE@@IFSUPP ambient.humidity@&lt;td ALIGN=\"CENTER\" VALIGN=\"TOP\" BGCOLOR=\"#000000\"&gt;&lt;table BORDER=\"0\"&gt;&lt;tr&gt;&lt;td ALIGN=\"CENTER\"&gt;Humidity&lt;br&gt;@IMG ambient.humidity@&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;@ENDIF@&lt;td ALIGN=\"CENTER\" VALIGN=\"TOP\" BGCOLOR=\"#000000\"&gt;&lt;table BORDER=\"0\"&gt;&lt;tr&gt;@IFSUPP battery.charge@@IFSUPP battery.voltage@&lt;td ALIGN=\"CENTER\"&gt;Charge&lt;br&gt;@IMG battery.charge width=90@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;Voltage&lt;br&gt;@IMG battery.voltage width=90@&lt;/td&gt;@ELSE@@IFSUPP battery.charge@&lt;td ALIGN=\"CENTER\"&gt;Charge&lt;br&gt;@IMG battery.charge@&lt;/td&gt;@ELSE@&lt;td ALIGN=\"CENTER\"&gt;Voltage&lt;br&gt;@IMG battery.voltage@&lt;/td&gt;@ENDIF@&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;&lt;td ALIGN=\"CENTER\" VALIGN=\"TOP\" BGCOLOR=\"#000000\"&gt;&lt;table BORDER=\"0\"&gt;&lt;tr&gt;@IFSUPP input.L2-L3.voltage@&lt;td ALIGN=\"CENTER\"&gt;L1-L2&lt;br&gt;@IMG input.L1-L2.voltage width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L2-L3&lt;br&gt;@IMG input.L2-L3.voltage width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L3-L1&lt;br&gt;@IMG input.L3-L1.voltage width=68@&lt;/td&gt;@ELSE@@IFSUPP input.L2-N.voltage@&lt;td ALIGN=\"CENTER\"&gt;L1-N&lt;br&gt;@IMG input.L1-N.voltage width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L2-N&lt;br&gt;@IMG input.L2-N.voltage width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L3-N&lt;br&gt;@IMG input.L3-N.voltage width=68@&lt;/td&gt;@ELSE@&lt;td ALIGN=\"CENTER\"&gt;&lt;br&gt;@IMG input.voltage@&lt;/td&gt;@ENDIF@&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;&lt;td ALIGN=\"CENTER\" VALIGN=\"TOP\" BGCOLOR=\"#000000\"&gt;&lt;table BORDER=\"0\"&gt;&lt;tr&gt;@IFSUPP output.L2-L3.voltage@&lt;td ALIGN=\"CENTER\"&gt;L1-L2&lt;br&gt;@IMG output.L1-L2.voltage width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L2-L3&lt;br&gt;@IMG output.L2-L3.voltage width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L3-L1&lt;br&gt;@IMG output.L3-L1.voltage width=68@&lt;/td&gt;@ELSE@@IFSUPP output.L2-N.voltage@&lt;td ALIGN=\"CENTER\"&gt;L1-N&lt;br&gt;@IMG output.L1-N.voltage width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L2-N&lt;br&gt;@IMG output.L2-N.voltage width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L3-N&lt;br&gt;@IMG output.L3-N.voltage width=68@&lt;/td&gt;@ELSE@&lt;td ALIGN=\"CENTER\"&gt;&lt;br&gt;@IMG output.voltage@&lt;/td&gt;@ENDIF@&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;&lt;td ALIGN=\"CENTER\" VALIGN=\"TOP\" BGCOLOR=\"#000000\"&gt;&lt;table BORDER=\"0\"&gt;&lt;tr&gt;@IFSUPP output.L2.power.percent@&lt;td ALIGN=\"CENTER\"&gt;L1&lt;br&gt;@IMG output.L1.power.percent width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L2&lt;br&gt;@IMG output.L2.power.percent width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L3&lt;br&gt;@IMG output.L3.power.percent width=68@&lt;/td&gt;@ELSE@@IFSUPP output.L2.realpower.percent@&lt;td ALIGN=\"CENTER\"&gt;L1&lt;br&gt;@IMG output.L1.realpower.percent width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L2&lt;br&gt;@IMG output.L2.realpower.percent width=68@&lt;/td&gt;&lt;td ALIGN=\"CENTER\"&gt;L3&lt;br&gt;@IMG output.L3.realpower.percent width=68@&lt;/td&gt;@ELSE@&lt;td ALIGN=\"CENTER\"&gt;&lt;br&gt;@IMG ups.load@&lt;/td&gt;@ENDIF@&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;script type=\"application/json\"&gt;{\t\"Date\": \"@DATE %d %m %y %X %Z@\",\t\"battery\" : {\t\t\"chargePercent\" : @VAR battery.charge@,\t\t\"voltageDc\" : @VAR battery.voltage@\t},\t\"input\" : {\t\t\"voltage\": @VAR input.voltage@\t},\t\"output\": {\t\t\"voltageAc\": @VAR output.voltage@\t},\t\"ups\": {\t\t\"model\": \"@VAR ups.model@\",\t\t\"loadPercent\": @VAR ups.load@,\t\t\"runtime\": \"@RUNTIME@\",@IFEQ ups.status OL@\t\t\"status\": \"ONLINE\"@ELSE@@IFEQ ups.status OB@\t\t\"status\": \"BATTERY\"@ENDIF@\t}}&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;" }, { "title": "Architecture Decision Record", "url": "/posts/architecture-decision-record-template/", "categories": "ways-of-working", "tags": "best-practice", "date": "2021-08-13 08:43:00 +0100", "snippet": "Architecture Decision Record template| Issue | Status | Date ||-------------------|-----------------|--------------------|| Whats the issue? | Is it decided? | Date decision made | References architecture_decisions-tree.pdf https://ardalis.com/getting-started-with-architecture-decision-records/ https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions# CSS frameworkContents:- [Architecture Decision Record template](#architecture-decision-record-template)- [CSS framework](#css-framework) - [Summary](#summary) - [Issue](#issue) - [Decision](#decision) - [Status](#status) - [Details](#details) - [Assumptions](#assumptions) - [Constraints](#constraints) - [Positions](#positions) - [Argument](#argument) - [Implications](#implications) - [Related](#related) - [Related decisions](#related-decisions) - [Related requirements](#related-requirements) - [Related artifacts](#related-artifacts) - [Related principles](#related-principles) - [Notes](#notes)## Summary### IssueWe want to use a CSS framework to create our web applications: * We want user experience to be fast and reliable, on all popular browsers and screen sizes. * We want rapid iteration on design, layout, UI/UX, etc. * We want responsive applications, especially for smaller screens such as on mobile devices, larger screens such as on 4K widescreens, and dynamic screens such as rotatable displays. ### DecisionDecided on Bulma.### StatusDecided on Bulma. Open to new CSS framework choices as they arrive.## Details### AssumptionsWe want to create web apps that are modern, fast, reliable, responsive, etc.Typical modern web apps are reducing/eliminating the use of jQuery because of multiple reasons: * Modern JavaScript in phasing in many capabilities that jQuery has provided, so jQuery is less needed, and there are better/faster/smaller modules that provide specific implementations * jQuery's broad approach is to do direct DOM manipulation, which is an anti-pattern for modern JavaScript frameworks (e.g. React, Vue, Svelte) * jQuery interferes with itself if it's loaded twice, etc.### ConstraintsIf we choose a CSS framework that uses jQuery, then we're stuck importing jQuery. For example, Semantic UI uses jQuery, and Tachyons does not.If we choose a CSS framework that is minimal, then we forego framework components that we may want now or soon. For example, Semantic UI provides an image carousel, and Tachyons does not.### PositionsWe considered using no framework. This still seems viable, especially because CSS grid provides much of what we need for our project..We considered many CSS frameworks using a quick shortlist triage: Bootstrap, Bulma, Foundation, Materialize, Semantic UI, Tachyons, etc. Our two selections for deeper review are Semantic UI (because it has the most-semantic approach) and Bulma (because it has the lightest-weight approach that provides the components we want now).We considered Semantic UI. This provides many components, including ones we want for our project: tabs, grids, buttons, etc. We did a pilot with Semantic UI two ways: using typical CDN files, and using NPM repos. We achieved success with Semantic UI in a static HTML page, but did not achieve success within our timebox to build a JavaScript SPA (primarly because of jQuery load issues). We discovered that other coders have been asking the Semantic UI developers to create a jQuery-free version, for the same reasons we have. Other coders have been requesting a jQuery-free version for many years, yet the developers have said no, and stated that any jQuery-free version would be too hard to write e.g. ~\"the Semantic UI project has more than 22,000 touchpoints that use jQuery\".Example with Semantic:```html&lt;div class=\"ui top attached tabular menu\"&gt; &lt;a class=\"item\"&gt;Alpha&lt;/a&gt; &lt;a class=\"item\"&gt;Bravo&lt;/a&gt;&lt;/div&gt;```We considered Bulma. Bulma has many similar capabilties as Semantic UI, although not as many sophisticated components. Bulma is built with modern techniques, such as no jQuery. Bulma has some third-party components, some of which we may want to use.Example with Bulma:``` html&lt;div class=\"tabs\"&gt; &lt;ul&gt; &lt;li&gt;&lt;a&gt;Alpha&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a&gt;Bravo&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;```### ArgumentAs above.Specifically, Semantic UI seems to have a caution flag both in terms of technology (i.e. so many jQuery touchpoints) and also in terms of leadership (i.e. jQuery-free was a hard no, rather than attemping a roadmap, or continous improvement, or donation fundraising, etc.).### ImplicationsIf we find a good non-jQuery CSS framework, this is generally helpful and good overall.## Related### Related decisionsThe CSS framework we choose may affect testability.### Related requirementsWe want to ship a purely-modern app fast. We do not want to spend time working on older frameworks (esp. Semantic UI) using older dependencies (esp. jQuery).### Related artifactsAffects all the typical HTML that will use the CSS.### Related principlesEasily reversible.Need for speed.## NotesAny notes here." }, { "title": "How to share network folder", "url": "/posts/creating-a-shared-folder/", "categories": "linux", "tags": "", "date": "2021-02-23 09:33:00 +0000", "snippet": "How to share network folderExcerpt from : https://www.makeuseof.com/set-up-network-shared-folder-ubuntu-with-samba/Want to share files with multiple devices on a single network? Create a shared folder on your Ubuntu machine using Samba.If you have ever wanted to easily share files on your home network across multiple operating systems, then look no further than Samba.This guide will show you how to set up a network shared folder on Ubuntu Linux using Samba. With the Samba server, you can easily share files on your network, regardless of whether you are using Windows, macOS, or Linux.What Is Samba?Samba is a file-sharing service that implements open source versions of the SMB suite of protocols, which was originally developed by Microsoft and IBM. Samba contains programs that allow it to interoperate with Microsoft Windows file sharing protocols.Samba also allows you to easily communicate with other clients using standard TCP/IP networking.Step 1: Installing SambaThis guide will use Ubuntu Linux 20.04 LTS, but the steps should work even if you are using Ubuntu 16.04 or later. Begin by updating your package source information.sudo apt updateThen, install Samba using the command below:sudo apt install sambaTo check if Samba has been successfully installed, run the following command:smbd --versionThe output should be similar to the one below.Step 2: Configuring SambaTo be able to share files securely with other network devices, you have to configure the Samba server. The main configuration file for Samba is located at /etc/samba/smb.conf on your PC. This guide uses the Vim text editor for editing the Samba configuration file, but feel free to use any other text editor of your choice.Note : You need to have administrative privileges to edit the configuration file.sudo vim /etc/samba/smb.confAdd the following lines to the bottom of the config file.[sambashare]comment= Network Shared Folder by Samba Server on Ubuntupath = /home/your_username/sambashareforce user = smbuserforce group = smbgroupcreate mask = 0664force create mode = 0664directory mask = 0775force directory mode = 0775public = yesread only = noRemember to update the path parameter with your username. You can get your username by running the following command:echo $USERTo exit the Vim editor after making your changes, simply type :wq and press the Enter key.Understanding the ConfigurationsHere is a brief description of the configuration lines that you just added. Section: A new section in the configuration file is represented by square brackets ([ ]). In this case, the section is [sambashare]. Comment: This line of code provides a brief outline of what this section is about. Especially, it is useful if you have several shared directory sections in the config file. Path: This is the path to the directory of your designated network shared folder. Force user: The system user that the Samba server will use for sharing files. Force group: The name of the group to which the Samba system user will belong. Create mask: This parameter will set permissions for newly created files in the shared folder. In this case, the value is 0664 which means that the owner of the file and the group will have read and write permissions while other users will only have read permissions. Force create mode: Works in conjunction with the create mask parameter in order to set the correct file permissions. Directory mask: This parameter determines the permissions for folders in the shared folder. Permissions of 0775, means that the owner and the group have read, write, and execute permissions, while others have read and execute permissions only. Force directory mode: This parameter works in collaboration with the directory mask to make sure that the correct directory permission is set. Public: This parameter specifies that this is a public folder on your network and that other devices can access it. Read only: Specifies the permissions for modifying the files within the shared folder.Step 3: Creating Samba ResourcesHaving configured the Samba server, now you have to create the necessary resources such as the Samba user and the directory to share. These resources will facilitate the process of sharing a folder on the network.1. Shared FolderYou need to create the shared folder in the path specified in the Samba config file above. This guide uses a shared folder named sambashare located in your home directory.Navigate to your home directory using the cd command.cd ~Then create the shared directory using the command below:mkdir -p sambashare2. Samba User and GroupThe next step is to create the Samba system user and group specified in the configuration file.You can create the Samba system group using the following command:sudo groupadd --system smbgroupNext, create the Samba system user using useradd.sudo useradd --system --no-create-home --group smbgroup -s /bin/false smbuserThe command above creates a system user and adds the user to the Samba group created above. Also since this is a system user, no home directory will be created.Step 3. Changing the Shared Folder OwnerOnce the Samba user and group are in place, you can now change the shared folder owner to the new user smbuser and the group to smbgroup. You can achieve this using the command below:sudo chown -R smbuser:smbgroup ~/sambashareFinally, issue the command below to give the group write access to the shared folder and the content inside it.sudo chmod -R g+w ~/sambashareStep 4: Restarting the Samba ServiceYou should restart the Samba service for the changes in the Samba configuration file to take effect.sudo systemctl restart smbdAfter the service restarts, you can check its status with the command below:sudo systemctl status smbdNote: If you have your firewall enabled, you should also add Samba to your enabled rules using the ufw command.sudo ufw enable sambaStep 5: Accessing the Shared FolderYour shared folder is now accessible by the devices on your network.On WindowsIn Windows, you can access the shared folder using Windows Explorer. You can start file explorer using the Windows + E keyboard shortcut.In the address bar, type \\\\ip_address_of_pc_with_shared_folder\\sambashare.Remember to replace with the correct IP address and shared folder name.The system will also ask you to enter the username and password of the user on the Linux PC.On UbuntuOn Ubuntu Linux, open the default file manager and click on the Other Locations button. Then, in the Connect to Server input, enter an IP address in the following format:smb://ip_adresss_of_pc_with_shared_folder/sambashareYou can either connect as a registered user or anonymous. Keep in mind that if you select Registered User from the dropdown, you’ll have to specify the credentials of the user.On macOSMac users can access the shared folder easily as well. In the Finder menu, click on the Network tab, and the computer with the public shared folder will be listed. Select it and you should be able to access the files.Sharing Files Between Multiple Devices EfficientlyThis guide has looked at how to share files on a network using Samba. With Samba, you can share files on a network regardless of the operating system that you are running on the devices.Not only Linux, but you can also configure a shared network folder on your Windows machine" }, { "title": "Definition of Done", "url": "/posts/definition-of-done/", "categories": "ways-of-working", "tags": "best-practice", "date": "2021-02-23 09:33:00 +0000", "snippet": "Taken from https://www.leadingagile.com/2017/02/definition-of-done/IS IT DONE, IS IT DONE DONE, OR IS IT DONE DONE DONE?If you’re in the business of application development, you’ve asked that question before. So what is the definition of done? When asking the question, it’s important to note who you are and your level in the organization. Delivery teams, program teams, and portfolio teams define done differently. What we know for sure, is that we need a clear definition of done at each level of the organization.DEFINITION OF DONEThe definition of done (DoD) is when all conditions, or acceptance criteria, that a software product must satisfy are met and ready to be accepted by a user, customer, team, or consuming system. We must meet the definition of done to ensure quality. It lowers rework, by preventing user stories that don’t meet the definition from being promoted to higher level environments. It will prevent features that don’t meet the definition from being delivered to the customer or user.USER STORIESThe most common use of DoD is on the delivery team level. Done on this level means the Product Owner reviewed and accepted the user story. Once accepted, the “done” user story will contribute to the team velocity. You must meet all of the defined criteria or the user story isn’t done.User Story DoD Examples Unit tests passed Code reviewed Acceptance criteria met Functional tests passed Non-Functional requirements met Product Owner accepts the User StoryFEATURESDone on this level may mean it qualifies to add to a release. Not all user stories need to be completed. Rather, it means the feature may be sufficient to satisfy the need. Once accepted, the done feature will contribute to the release velocity. Again, you must meet all of the defined criteria or the feature isn’t done.Feature DoD Examples: Acceptance criteria met Integrated into a clean build Promoted to higher level environment Automated regression tests pass Feature level functional tests passed Non-Functional requirements met Meets compliance requirements Functionality documented in necessary user user documentationEPICSDone on this level may refer to a organizational strategic priority, portfolio plan item, or some other collection of features that satisfied a market need. Not all user stories or features need to be completed. Rather, the epic may be sufficient to satisfy the need. Once accepted, the done epic will contribute to throughput calculations to see if the supply is in balance with demand.Epic DoD Examples: Non-Functional requirements met End-to-end integration completed Regression tests pass Promoted to production environment Meets defined market expectationsSUMMARYJust as the definition of ready is super important, so is the definition of done. Never start work on something until you have agreed on the definition. Be consistent. Be clear. Have a shared understanding." }, { "title": "Sizing guide", "url": "/posts/sizing-guide/", "categories": "ways-of-working", "tags": "agile, best-practice", "date": "2021-02-22 09:43:00 +0000", "snippet": "Product owners and managers always want dates or the number of days work will take to be completed. The problem is that WE developers cannot say for sure, but what we can agree on is how big a problem actually is.Many companies and developers have come up with different ways to calculate the size of a user story from using numbers to T-shirt sizes. The Agile methodology uses a system known as Planning poker.Planning Poker, involves the team taking a user story with agreed acceptance criteria, discussing it and showing a number from the Fibonacci sequence on a card.The sequence usually used is 1, 2, 3, 5, 8, 13, 20….It is recommended that User Stories deemed larger than 8 should be split across multiple user stories." }, { "title": "Feature flags", "url": "/posts/feature-flags/", "categories": "ways-of-working", "tags": "best-practice", "date": "2021-02-22 09:43:00 +0000", "snippet": "Taken from https://www.optimizely.com/uk/optimization-glossary/feature-flags/What are Feature Flags?Feature flags are a software development technique that turns certain functionality on and off, without deploying new code. This allows for better control and more experimentation over the full lifecycle of features.The idea behind feature flags is to build conditional feature branches into code in order to make logic available only to certain groups of users at a time. If the flag is “on” new code is executed, if the flag is “off” the code is skipped.Also referred to as feature toggles, feature flags are a best practice in DevOps, often occurring within distributed version control systems." }, { "title": "Agile sprint calendar", "url": "/posts/agile-diary/", "categories": "ways-of-working", "tags": "agile", "date": "2019-08-03 18:33:00 +0100", "snippet": "Example Diary Week Monday Tuesday Wednesday Thursday Friday One Refinement 1h   Sprint Review 30mRetrospective 30mSprint Planning 30m Refinement 1h   Two Refinement 1h     Refinement 1h   " }, { "title": "Code Design Patterns", "url": "/posts/code-design-patterns/", "categories": "reading", "tags": "design-patterns", "date": "2019-02-08 12:41:00 +0000", "snippet": "Code Design PatternsCreational PatternsAbstract FactoryCreates an instance of several families of classesBuilderSeparates object construction from its representationFactory MethodCreates an instance of several derived classesPrototypeA fully initialized instance to be copied or clonedSingletonA class of which only a single instance can existStructural PatternsAdapterMatch interfaces of different classesBridgeSeparates an object’s interface from its implementationCompositeA tree structure of simple and composite objectsDecoratorAdd responsibilities to objects dynamicallyFacadeA single class that represents an entire subsystemFlyweightA fine-grained instance used for efficient sharingProxyAn object representing another objectBehavioral PatternsChain of ResponsibilityA way of passing a request between a chain of objectsCommandEncapsulate a command request as an objectInterpreterA way to include language elements in a programIteratorSequentially access the elements of a collectionMediatorDefines simplified communication between classesMementoCapture and restore an object’s internal stateObserverA way of notifying change to a number of classesStateAlter an object’s behavior when its state changesStrategyEncapsulates an algorithm inside a classTemplate MethodDefer the exact steps of an algorithm to a subclassVisitorDefines a new operation to a class without change" }, { "title": "Simplifying UI testing", "url": "/posts/test-id/", "categories": ".net", "tags": "testing, c#, aspnet", "date": "2019-01-14 13:33:00 +0000", "snippet": "How to make it easier for UI test engineers to take a dependency on UI elements.[HtmlTargetElement(Attributes = \"test-id\")]public class TestIdHelper : TagHelper{ private readonly bool _displayTestId; public TestIdHelper(IConfiguration configuration) { bool.TryParse(configuration[\"IsTesting\"], out bool isTesting); _displayTestId = isTesting; } // PascalCase gets translated into kebab-case. public string TestId { get; set; } public override void Process(TagHelperContext context, TagHelperOutput output) { output.Attributes.RemoveAll(\"test-id\"); if(_displayTestId) { output.Attributes.SetAttribute(\"tId\", TestId); } }}Example of use&lt;li&gt;&lt;asp-controller=\"Manage\" asp-action=\"Index\" test-id=\"mnuManage\"&gt;@Localizer[\"Dashboard\"]&lt;/a&gt;&lt;/li&gt;" }, { "title": "Apple Mac Keyboard Shortcuts", "url": "/posts/mac-keyboard-shortcuts/", "categories": "mac", "tags": "misc", "date": "2016-09-23 17:33:00 +0100", "snippet": "Mac keyboard shortcutsBy pressing a combination of keys, you can do things that normally need a mouse, trackpad, or other input device.To use a keyboard shortcut, hold down one or more modifier keys while pressing the last key of the shortcut.For example, to use the shortcut Command-C (copy), hold down Command + C, then release both keys. Mac menus and keyboards often use symbols for certain keys, including the modifier keys:Keys Command ⌘ Shift ⇧ Option ⌥ Control ⌃ Caps Lock ⇪ FnIf you’re using a keyboard made for Windows PCs, use the Alt key instead of Option, and the Windows logo key instead of Command. Some Mac keyboards and shortcuts use special keys in the top row, which include icons for volume, display brightness, and other functions.Press the icon key to perform that function, or combine it with the Fn key to use it as an F1, F2, F3 or other standard function key.To learn more shortcuts, check the menus of the app you’re using. Every app can have its own shortcuts, and shortcuts that work in one app may not work in another.Cut, copy, paste, and other common shortcutsCommand - X\tCut: Remove the selected item and copy it to the ClipboardCommand - C\tCopy the selected item to the Clipboard. This also works for files in the FinderCommand - V\tPaste the contents of the Clipboard into the current document or app. This also works for files in the FinderCommand - Z\tUndo the previous command. You can then press Command-Shift-Z to Redo, reversing the undo command. In some apps, you can undo and redo multiple commandsCommand - A\tSelect All itemsCommand - F\tFind: Open a Find window, or find items in a documentCommand - G\tFind Again: Find the next occurrence of the item previously found. To find the previous occurrence, press Command-Shift-GCommand - H\tHide the windows of the front app. To view the front app but hide all other apps, press Command-Option-HCommand - M\tMinimize the front window to the Dock. To minimize all windows of the front app, press CCommand-Option-MCommand - N\tNew: Open an new document or windowCommand - O\tOpen the selected item, or open a dialog to select a file to openCommand - P\tPrint the current documentCommand - S\tSave the current documentCommand - W\tClose the front window. To close all windows of the app, press Command-Option-WCommand - Q\tQuit the appOption-Command-Esc\tForce Quit: Choose an app to force quit. Or press Command-Shift-Option-Esc and hold for 3 seconds to force just the front app to quitCommand–Space bar\tSpotlight: Show or hide the Spotlight search field. To perform a Spotlight search from a Finder window, press Command–Option–Space bar. If you use multiple input sources to type in different languages, these shortcuts change input sources instead of showing SpotlightSpace bar\tQuick Look: Use Quick Look to preview the selected itemCommand-Tab\tSwitch apps: Switch to the next most recently used app among your open appsShift-Command-Tilde (~) Switch windows: Switch to the next most recently used window of the front appShift-Command-3 Screenshot: Take a screenshot of the entire screen. Learn more screenshot shortcutsCommand-Comma (,)\tPreferences: Open preferences for the front appSleep, log out, and shut down shortcutsPower button Tap to turn on your Mac or wake your Mac from sleep Hold for 1.5 seconds while your Mac is awake to display a dialog asking if you want to restart, sleep, or shut down. If you don’t want to wait 1.5 seconds, press Control–Power button or Control–Media Eject Hold for 5 seconds to force your Mac to turn off.Control–Command–Power button to force your Mac to restartControl–Shift–Power button or Media Eject to put your displays to sleepControl–Command–Media Eject Quit all apps, then restart your Mac. If any open documents have unsaved changes, you’ll be asked whether you want to save themControl–Option–Command–(Power button or Media Eject) Quit all apps, then shut down your Mac. If any open documents have unsaved changes, you’ll be asked whether you want to save themShift-Command-Q Log out of your OS X user account. You’ll be asked to confirmOption-Shift-Command-Q Log out of your OS X user account immediately, without being asked to confirmDocument shortcutsCommand-B Boldface the selected text, or turn boldfacing on or offCommand-I Italicize the selected text, or turn italics on or offCommand-U Underline the selected text, or turn underlining on or offCommand-T Show or hide the Fonts windowCommand-D Select the Desktop folder from within an Open dialog or Save dialogControl-Command-D Show or hide the definition of the selected wordShift-Command-Colon (:) Display the Spelling and Grammar windowCommand-Semicolon (;) Find misspelled words in the documentOption-Delete Delete the word to the left of the insertion pointControl-H Delete the character to the left of the insertion point. Or use DeleteControl-D Delete the character to the right of the insertion point. Or use Fn-DeleteFn-Delete Forward delete on keyboards that don’t have a Forward Delete key. Or use Control-DControl-K Delete the text between the insertion point and the end of the line or paragraphCommand-Delete Select Delete or Don’t Save in a dialog that contains a Delete or Don’t Save buttonFn–Up Arrow Page Up: Scroll up one pageFn–Down Arrow Page Down: Scroll down one pageFn–Left Arrow Home: Scroll to the beginning of a documentFn–Right Arrow End: Scroll to the end of a documentCommand–Up Arrow Move the insertion point to the beginning of the documentCommand–Down Arrow Move the insertion point to the end of the documentCommand–Left Arrow Move the insertion point to the beginning of the current lineCommand–Right Arrow Move the insertion point to the end of the current lineOption–Left Arrow Move the insertion point to the beginning of the previous wordOption–Right Arrow Move the insertion point to the end of the next wordShift–Command–Up Arrow Select the text between the insertion point and the beginning of the documentShift–Command–Down Arrow Select the text between the insertion point and the end of the documentShift–Command–Left Arrow Select the text between the insertion point and the beginning of the current lineShift–Command–Right Arrow Select the text between the insertion point and the end of the current lineShift–Up Arrow Extend text selection to the nearest character at the same horizontal location on the line aboveShift–Down Arrow Extend text selection to the nearest character at the same horizontal location on the line belowShift–Left Arrow Extend text selection one character to the leftShift–Right Arrow Extend text selection one character to the rightOption–Shift–Up Arrow Extend text selection to the beginning of the current paragraph, then to the beginning of the following paragraph if pressed againOption–Shift–Down Arrow Extend text selection to the end of the current paragraph, then to the end of the following paragraph if pressed againOption–Shift–Left Arrow Extend text selection to the beginning of the current word, then to the beginning of the following word if pressed againOption–Shift–Right Arrow Extend text selection to the end of the current word, then to the end of the following word if pressed againControl–A Move to the beginning of the line or paragraphControl–E Move to the end of a line or paragraphControl–F Move one character forwardControl–B Move one character backwardControl–L Center the cursor or selection in the visible areaControl–P Move up one lineControl–N Move down one lineControl–O Insert a new line after the insertion pointControl–T Swap the character behind the insertion point with the character in front of the insertion pointCommand–Left Curly Bracket ({) Left alignCommand–Right Curly Bracket (}) Right alignShift–Command–Vertical bar (|) Center alignOption–Command-F Go to the search fieldOption–Command-T Show or hide a toolbar in the appOption–Command-C Copy Style: Copy the formatting settings of the selected item to the ClipboardOption–Command-V Paste Style: Apply the copied style to the selected itemOption–Shift-Command-V Paste and Match Style: Apply the style of the surrounding content to the item pasted within that contentOption–Command-I Show or hide the inspector windowShift–Command–-P Page setup: Display a window for selecting document settingsShift–Command–-S Display the Save As dialog, or duplicate the current documentShift–Command––Minus sign (-) Decrease the size of the selected itemShift–Command––Plus sign (+) Increase the size of the selected item. Command–Equal sign (=) performs the same functionShift–Command–Question mark (?) Open the Help menuFinder shortcutsCommand-D Duplicate the selected files.Command-E Eject the selected disk or volume.Command-F Start a Spotlight search in the Finder window.Command-I Show the Get Info window for a selected file.Shift-Command-C Open the Computer window.Shift-Command-D Open the desktop folder.Shift-Command-F Open the All My Files window.Shift-Command-G Open a Go to Folder window.Shift-Command-H Open the Home folder of the current OS X user account.Shift-Command-I Open iCloud Drive.Shift-Command-K Open the Network window.Option-Command-L Open the Downloads folder.Shift-Command-O Open the Documents folder.Shift-Command-R Open the AirDrop window.Shift-Command-T Add selected Finder item to the Dock (OS X Mountain Lion or earlier)Control-Shift-Command-T Add selected Finder item to the Dock (OS X Mavericks or later)Shift-Command-U Open the Utilities folder.Option-Command-D Show or hide the Dock. This often works even when you’re not in the Finder.Control-Command-T Add the selected item to the sidebar (OS X Mavericks or later).Option-Command-P Hide or show the path bar in Finder windows.Option-Command-S Hide or show the Sidebar in Finder windows.Command–Slash (/) Hide or show the status bar in Finder windows.Command-J Show View Options.Command-K Open the Connect to Server window.Command-L Make an alias of the selected item.Command-N Open a new Finder window.Shift-Command-N Create a new folder.Option-Command-N Create a new Smart Folder.Command-R Show the original file for the selected alias.Command-T Show or hide the tab bar when a single tab is open in the current Finder window.Shift-Command-T Show or hide a Finder tab.Option-Command-T Show or hide the toolbar when a single tab is open in the current Finder window.Option-Command-V Move: Move the files in the Clipboard from their original location to the current location.Option-Command-Y View a Quick Look slideshow of the selected files.Command-Y Use Quick Look to preview the selected files.Command-1 View the items in the Finder window as icons.Command-2 View the items in a Finder window as a list.Command-3 View the items in a Finder window in columns.Command-4 View the items in a Finder window with Cover Flow.Command–Left Bracket ([) Go to the previous folder.Command–Right Bracket (]) Go to the next folder.Command–Up Arrow Open the folder that contains the current folder.Command–Control–Up Arrow Open the folder that contains the current folder in a new window.Command–Down Arrow Open the selected item.Command–Mission Control Show the desktop. This works even when you’re not in the Finder.Command–Brightness Up Turn Target Display Mode on or off.Command–Brightness Down Turn display mirroring on or off when your Mac is connected to more than one display.Right Arrow Open the selected folder. This works only when in list view.Left Arrow Close the selected folder. This works only when in list view.Option–double-click Open a folder in a separate window and close the current window.Command–double-click Open a folder in a separate tab or window.Command-Delete Move the selected item to the Trash.Shift-Command-Delete Empty the Trash.Option-Shift-Command-Delete Empty the Trash without confirmation dialog.Command-Y Use Quick Look to preview the files.Option–Brightness Up Open Displays preferences. This works with either Brightness key.Option–Mission Control Open Mission Control preferences.Option–Volume Up Open Sound preferences. This works with any of the volume keys.Command key while dragging Move the dragged item to another volume or location. The pointer changes while you drag the item.Option key while dragging Copy the dragged item. The pointer changes while you drag the item.Option-Command while dragging Make an alias of the dragged item. The pointer changes while you drag the item.Option-click a disclosure triangle Open all folders within the selected folder. This works only when in list view.Command-click a window title See the folders that contain the current folder." }, { "title": "Git Cheat Sheet for TFS Users", "url": "/posts/git-cheat-sheat-for-tfs-users/", "categories": "git", "tags": "", "date": "2016-09-23 10:33:00 +0100", "snippet": "Git Cheat Sheet for TFS UsersIf you’re used to a centralized version control system like Team Foundation Server Version Control (TFVC), it can be a little tricky to make the move to Git — not because it’s all that hard — mostly because the terminology is completely different. So, are you a TFVC user who needs to wrap your head around Git? Here’s a little cheat sheet for you. TFS Version Control Git Workspace Repository (aka. “Repo”) Get Latest (First time) Clone Get Latest (After first time) Pull Check in Commit + Push Check out (just start typing) Branch Branch Merge Merge Code Review “pull request” Shelveset Stash Label Tag " }, { "title": "How to find where .net framework classes have been moved between versions", "url": "/posts/how-to-find-where-dot-net-framework-classes-have-been-moved-between-versions/", "categories": ".net", "tags": "c#", "date": "2016-08-25 19:36:00 +0100", "snippet": "I found this useful website which enables you to searh where classes and methods have been moved to between versions of .net framework eg. FileStreamhttp://packagesearch.azurewebsites.netI heard about this from the .Net rocks podcast - 16th August 2016" }, { "title": "How to convert IAsync to Task Await Async", "url": "/posts/convert-iasync-to-async-await/", "categories": ".net", "tags": "c#, async-pattern", "date": "2016-08-25 18:34:00 +0100", "snippet": "var result = await Task&lt;OssObject&gt;.Factory.FromAsync(client.BeginGetObject, client.EndGetObject, bucketName, key, null);OssObject is the return object in method click.BeginGetObjectclient.EndGetObject is the method which gets called once the BeginGetObject has completed.bucketName happens to be an argument passed into BeginGetObject." }, { "title": "Immediately-Invoked Function Expression", "url": "/posts/imediately-invoked-function-expression/", "categories": ".net", "tags": "aspnet, js", "date": "2016-07-23 18:54:00 +0100", "snippet": "(function ($) { var model = { init: function () { } }, view = { init: function () { model.init(); } }, controller = { init: function () { view.init(); } }; controller.init();}(window.jQuery));(function ($) { var model = { init: function () { } }, view = { init: function () { model.init(); this.$btnSendCode = $('#btnSendCode').click(this.btnSendCodeClick); this.$txtUsername = $('#Username'); this.$modal = $('#modal').on('shown.bs.modal', this.reAlignModal); this.$modalBodyText = this.$modal.find('.modal-body'); $(window).on(\"resize\", function () { $(\".modal:visible\").each(view.reAlignModal); }); $(\"#modalTemplate\").template(\"modalTemplate\"); }, $txtUsername: null, $btnSendCode: null, btnSendCodeClick: function () { var mn = view.$txtUsername.val(); controller.sendCodeRequest(mn); }, $modal: null, $modalHeader: null, $modalBodyText: null, modalShow: function (dataObject) { $.tmpl(\"modalTemplate\", dataObject).appendTo(this.$modalBodyText.empty()); this.$modal.modal('show'); }, reAlignModal: function () { var $modalDialog = $(this).find(\".modal-dialog\"); $modalDialog.css(\"margin-top\", Math.max(0, ($(window).height() - $modalDialog.height()) / 3)); } }, controller = { init: function () { view.init(); }, sendCodeRequest: function (mobileNumber) { var postData = { mobileNumber: mobileNumber }; addAntiForgeryToken(postData); $.ajax({ cache: false, type: \"POST\", url: \"@Url.Action(\"SendReminder\", \"CustomCustomer\")\", data: postData, dataType: \"json\", success: controller.sendCodeResponseSuccess, error: controller.sendCodeResponseError }); }, sendCodeResponseSuccess: function (data, textStatus, jqXHR) { if (data.isDistributorCustomer) { view.modalShow({ distributor: { name: data.distributorCompanyName, email: data.distributorEmailAddress, phone: data.distributorPhoneNumber, hasName: data.distributorCompanyName !== null } }); } else { view.modalShow({ isSent: true }); } }, sendCodeResponseError: function (jqXHR, textStatus, errorThrown) { if (jqXHR.responseJSON == null || jqXHR.responseJSON.Error == null) return; view.modalShow({ error: jqXHR.responseJSON.Error }); } }; $(document).ready(controller.init);}(window.jQuery));// CSRF (XSRF) securityfunction addAntiForgeryToken(data) { //if the object is undefined, create a new one. if (!data) { data = {}; } //add token var tokenInput = $('input[name=__RequestVerificationToken]'); if (tokenInput.length) { data.__RequestVerificationToken = tokenInput.val(); } return data;};" }, { "title": "Linq 'Join' example", "url": "/posts/linq-join-example/", "categories": ".net", "tags": "c#, linq", "date": "2016-05-30 19:47:00 +0100", "snippet": "Examplevar joined = from Item1 in list1 join Item2 in list2 on Item1.Id equals Item2.Id // join on some property select new { Item1, Item2 };" }, { "title": "Linq 'Group by' example", "url": "/posts/linq-group-by-example/", "categories": ".net", "tags": "c#, linq", "date": "2016-03-21 11:55:00 +0000", "snippet": "Examplevar query = (from t in Transactions group t by new {t.MaterialID, t.ProductID} into grp select new { grp.Key.MaterialID, grp.Key.ProductID, Quantity = grp.Sum(t =&gt; t.Quantity) }).ToList();From http://stackoverflow.com/questions/847066/group-by-multiple-columns" }, { "title": "Splitting a collection over multiple threads", "url": "/posts/splitting-a-collection-over-multiple-threads/", "categories": ".net", "tags": "c#", "date": "2013-10-24 14:24:00 +0100", "snippet": "Inspired by http://www.drdobbs.com/windows/custom-parallel-partitioning-with-net-4/224600406?pgno=4.net 4 source code [TestMethod] public void TestMethod2() { var list = new List&lt;CustomerNotificationReply&gt;(); for (var i = 0; i &lt; 1000; i++) { list.Add(new CustomerNotificationReply() { DateTime = DateTime.Now, NotificationId = 895, ReplyType = new Random((int)DateTime.Now.Ticks).Next(1, 12) }); } var partitions = Partitioner.Create(list.ToArray()).GetPartitions(Environment.ProcessorCount); var tasks = (from partition in partitions select Task.Factory.StartNew(() =&gt; { using (partition) body(partition); })).ToArray(); Task.WaitAll(tasks);}private void body(IEnumerator&lt;CustomerNotificationReply&gt; partition){ INotificationReplyDAL dal = new NotificationReplyDAL(); while (partition.MoveNext()) { var x = partition.Current; dal.InsertCustomerNotificationReply(x); }}" } ]
